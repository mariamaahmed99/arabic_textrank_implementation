{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This implementation of the textrank algorithm has been adapted from https://github.com/prateekjoshi565/textrank_text_summarization/blob/master/TestRank_Text_Summarization.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-10T06:50:03.105179Z",
     "start_time": "2019-11-10T06:50:01.715831Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "WeptlGXN2MnF",
    "outputId": "b376a137-c4d7-4b78-f8ce-3fc43f948c1f"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')# one time execution\n",
    "stop_words = stopwords.words('arabic')\n",
    "nltk.download('punkt') # one time execution\n",
    "import re\n",
    "from nltk.cluster.util import cosine_distance\n",
    "from nltk.tokenize import word_tokenize\n",
    "import math\n",
    "import networkx as nx\n",
    "from operator import itemgetter\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "be2uYG7PombQ"
   },
   "source": [
    "# Clean sentences of punctuation marks and stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-10T06:50:03.145436Z",
     "start_time": "2019-11-10T06:50:03.137586Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "RX_NFApzIkmC"
   },
   "outputs": [],
   "source": [
    "# function to remove stopwords\n",
    "def remove_stopwords(sen):\n",
    "    sen_new = \" \".join([i for i in sen if i not in stop_words])\n",
    "    return sen_new\n",
    "\n",
    "from string import punctuation\n",
    "punctuation += '،؛؟'\n",
    "punctuation+='123456789'\n",
    "def remove_punctuation(sen):\n",
    "    sen_new = \" \".join([i for i in sen if i not in punctuation])\n",
    "    return sen_new\n",
    "\n",
    "def sentence_cleaner(sen):\n",
    "    clean_sentences = [remove_stopwords(r.split()) for r in sentences]\n",
    "    clean_sentences = [remove_punctuation(r.split()) for r in clean_sentences]\n",
    "    return clean_sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1bh9L2pqL3gp"
   },
   "source": [
    "The next step is to find similarities among the sentences. We will use cosine similarity to find similarity between a pair of sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-10T06:50:03.156071Z",
     "start_time": "2019-11-10T06:50:03.148157Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "gJaB9OVwjIE_"
   },
   "outputs": [],
   "source": [
    "def sentence_similarity(sent1, sent2):\n",
    "    all_words = list(set(word_tokenize(sent1)))\n",
    "    all_words= all_words+list(set(word_tokenize(sent2)))\n",
    "    vector1 = [0] * len(all_words)\n",
    "    vector2 = [0] * len(all_words)\n",
    "    sent1 = word_tokenize(sent1) \n",
    "    sent2 = word_tokenize(sent2)\n",
    "    for w in sent1:\n",
    "        vector1[all_words.index(w)] += 1\n",
    "    \n",
    "    for w in sent2: \n",
    "        vector2[all_words.index(w)] += 1\n",
    "    cosine_dist = 1 - cosine_distance(vector1, vector2) \n",
    "    if math.isnan((1-cosine_distance(vector1, vector2))):\n",
    "            cosine_dist = 0\n",
    "    return cosine_dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4Guhn-7YjIFB"
   },
   "source": [
    "## Sim matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-10T06:50:03.163541Z",
     "start_time": "2019-11-10T06:50:03.158943Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "Xtx6_41ZjIFC"
   },
   "outputs": [],
   "source": [
    "def get_sim_matrix(clean_sentences):\n",
    "    sim_mat = np.zeros([len(clean_sentences), len(clean_sentences)])\n",
    "    for i in range(len(clean_sentences)):\n",
    "        for j in range(len(clean_sentences)):\n",
    "            sim_mat[i][j] = sentence_similarity(clean_sentences[i],clean_sentences[j])\n",
    "    return sim_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-10T06:50:03.274938Z",
     "start_time": "2019-11-10T06:50:03.165395Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "CAQUnNRWL_tA"
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_ranked_sentences(sim_mat):\n",
    "    nx_graph = nx.from_numpy_array(sim_mat)\n",
    "    scores = nx.pagerank(nx_graph)\n",
    "    ranked_sentences = sorted(((scores[i],s) for i,s in enumerate(sentences)), reverse=True)\n",
    "    return ranked_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-10T08:48:18.947408Z",
     "start_time": "2019-11-10T08:48:18.936604Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "qGmbRUbhjIFG"
   },
   "outputs": [],
   "source": [
    "def summary_genarator(sentences, percentage):\n",
    "    clean_sentences = sentence_cleaner(sentences)\n",
    "    sim_mat = get_sim_matrix(clean_sentences)\n",
    "    ranked_sentences = get_ranked_sentences(sim_mat)\n",
    "    # Generate summary \n",
    "    sn = math.floor(percentage*len(sentences)/100) if math.floor(percentage*len(sentences)/100) is not 0 else 1\n",
    "    gen_summ = []\n",
    "    for i in range(sn):\n",
    "        gen_summ.append(ranked_sentences[i][1]) \n",
    "    return gen_summ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "42CeP4CQBPdh"
   },
   "source": [
    "### Different cosine similairty function used than in the beginning of code because the first both takes and returns 2d arrays."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "g_Z-8xV6o_2g"
   },
   "source": [
    "# Testing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-10T08:47:10.991323Z",
     "start_time": "2019-11-10T08:47:10.976809Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "pP5H76eNcKTM",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_summ_accuracy(gen_summ, correct_summ):\n",
    "    highestSimilarity = avg = 0\n",
    " \n",
    "    similarityScores = list()\n",
    "    for i in range(len(correct_summ)):\n",
    "        for j in range(len(gen_summ)):\n",
    "            similarity = sentence_similarity(correct_summ[i], gen_summ[j])\n",
    "            if  similarity > highestSimilarity:\n",
    "                highestSimilarity = similarity\n",
    "        similarityScores.append(highestSimilarity)\n",
    "        avg+=highestSimilarity\n",
    "        highestSimilarity=0\n",
    "\n",
    "    avg=avg/len(similarityScores)\n",
    "    return(avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the generated summaries against the human generates summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-10T08:52:13.485269Z",
     "start_time": "2019-11-10T08:48:21.722851Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "fMquAl5xjIFM"
   },
   "outputs": [],
   "source": [
    "# assign percentage for summary size\n",
    "percentage = 10\n",
    "\n",
    "# path to folder containing test articles\n",
    "folder_articles = \"EASC/EASC-UTF-8\"\n",
    "\n",
    "data = {'A 10':[],\n",
    "        'B 10':[],\n",
    "        'C 10':[],\n",
    "        'D 10':[],\n",
    "        'E 10':[],\n",
    "        'Max 10':[],\n",
    "        'A 20':[],\n",
    "        'B 20':[],\n",
    "        'C 20':[],\n",
    "        'D 20':[],\n",
    "        'E 20':[],\n",
    "        'Max 20':[],\n",
    "        'A 30':[],\n",
    "        'B 30':[],\n",
    "        'C 30':[],\n",
    "        'D 30':[],\n",
    "        'E 30':[],\n",
    "        'Max 30':[],\n",
    "        'A 40':[],\n",
    "        'B 40':[],\n",
    "        'C 40':[],\n",
    "        'D 40':[],\n",
    "        'E 40':[],\n",
    "        'Max 40':[]}\n",
    " \n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "#loop over all articles\n",
    "for x in range(1,154):\n",
    "    print(\"------------Testing article #\"+str(x)+\"------------\")\n",
    "    #list variable that stores all percentage accuracies for each of the 5 summaries + max value to be added \n",
    "    #directly to dataframe\n",
    "    list_accuracies = []\n",
    "    \n",
    "    for y in range(10,41,10):\n",
    "        print(\"------------Testing \"+str(y)+\"% summaries accuracy------------\")\n",
    "\n",
    "\n",
    "        #find path of folder containing article for each topic\n",
    "        article_path = folder_articles+'/Articles/Topic'+str(x)\n",
    "\n",
    "        #variable to store maximum of the 5 percentage accuracies\n",
    "        maximum = 0\n",
    "        #use os.walk to get the file path\n",
    "        for file in os.walk(article_path, topdown=True): \n",
    "            \n",
    "            #retrieve path of article\n",
    "            sentences_path = article_path+'/'+file[2][0]\n",
    "\n",
    "            #open the file and assign sentences of the article to variable sentences\n",
    "            with open(sentences_path, 'r', encoding = \"utf-8\", errors='ignore') as f:\n",
    "                sentences = f.read()\n",
    "\n",
    "            #perform basic cleaning of sentences to remove charaters found in the articles\n",
    "            sentences = sentences.replace(\"\\n\", \"\")\n",
    "            sentences = sentences.replace(\"\\ufeff\", \"\").split(\".\")\n",
    "\n",
    "            #remove any empty sentences\n",
    "            for sent in sentences:\n",
    "                if sent is \"\":\n",
    "                    sentences.remove(sent)  \n",
    "\n",
    "            #generate summary\n",
    "            gen_summ = summary_genarator(sentences, y)\n",
    "    ##FINDING HUMAN GEBERATED SUMMARIES OF EACH ARTICLE\n",
    "\n",
    "            #get path to folder where generated summaries of each topic are\n",
    "            summary_path = folder_articles + '/MTurk/Topic'+str(x)\n",
    "\n",
    "            \n",
    "            #loop over all files in folder \n",
    "            for files in os.walk(summary_path, topdown=True):\n",
    "                #get list of all summ path names to open one by one\n",
    "                list_correct_summ_paths = files[2]\n",
    "                \n",
    "                #loop over all correct summaries\n",
    "                for l in list_correct_summ_paths:\n",
    "\n",
    "                    #path to each summary \n",
    "                    s_path = summary_path+'/'+l\n",
    "\n",
    "                    #open the file and assign sentences of the summary to variable sentences\n",
    "                    with open(s_path, 'r', encoding = \"utf-8\", errors='ignore') as f2:\n",
    "                        correct_summ = f2.read()\n",
    "\n",
    "                    #perform basic cleaning of sentences to remove charaters found in the articles\n",
    "                    correct_summ = correct_summ.replace(\"\\n\", \"\")\n",
    "                    correct_summ = correct_summ.replace(\"\\ufeff\", \"\").split(\".\")\n",
    "\n",
    "                    #removing empty sentences\n",
    "                    while(\"\" in correct_summ) : \n",
    "                        correct_summ.remove(\"\") \n",
    "\n",
    "                    #get the similarity percentage between generated summary and actual accuracy\n",
    "                    list_accuracies.append(get_summ_accuracy(gen_summ,correct_summ))\n",
    "            #get maximum of percentages to represent similarity of generated summary to actual summary\n",
    "            maximum = max(list_accuracies)\n",
    "\n",
    "\n",
    "            #add the maximum to the list of accuracies to be added to the data frame\n",
    "            list_accuracies.append(maximum)\n",
    "\n",
    "            #Add a new row to the dataframe\n",
    "    df = df.append(pd.Series(list_accuracies, index =['A 10','B 10','C 10','D 10','E 10','Max 10', 'A 20','B 20','C 20','D 20','E 20','Max 20', 'A 30','B 30','C 30','D 30','E 30','Max 30', 'A 40','B 40','C 40','D 40','E 40','Max 40']),ignore_index=True)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Textrank_without_embedding_with_walk.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
